{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "bojbginpf7oxb6msyo43",
   "authorId": "2998447895159",
   "authorName": "AAGARWAL",
   "authorEmail": "aagarwal@guidepoint.com",
   "sessionId": "5e484f9d-bc2c-482b-b67e-f0dae5151348",
   "lastEditTime": 1742308222136
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom pandas.tseries.offsets import *\nfrom nltk.corpus import stopwords\nimport nltk\nfrom collections import Counter\nimport re\nfrom colorama import Fore\n\nimport snowflake.snowpark as snowpark",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1f74e521-6d3a-4c98-93cd-5a130b84a17a",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "def data_import():\n    session = snowpark.context.get_active_session()\n\n    query = \"\"\"SELECT * FROM research.kdolgin.unique_descriptions_keep limit 300000\"\"\"\n         \n    try:\n        df = session.sql(query).to_pandas()\n        return df\n        \n    except Exception as e:\n        print(f\"Error: {e}\")\n        return pd.DataFrame()\n    \n    return xf\n\ndata = data_import()\nprint(f\"Count of records : {data.count()}\")\ndata.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "19962ec9-3598-4b35-9a9a-da0e026e6cc1",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "data[\"COMBINED_TEXT\"] = (\n    # data[\"SOURCE_DESCRIPTION\"] + \" \" +\n    data[\"LVL3_TITLE\"].fillna('') + \" \" +\n    data[\"LVL6_GMDN_TT_NAME\"].fillna('') + \" \" +\n    data[\"BRAND_NAME_CLEAN\"].fillna('') + \" \" +\n    data[\"DEVICE_SYNONYM_LIST\"].fillna('') + \" \" +\n    data[\"MANUFACTURER_SUBMITTED_DESCRIPTION_CLEAN\"].fillna('') + \" \" +\n    data[\"UNSPSC_TITLE\"].fillna('') + \" \" +\n    data[\"GMDN_PT_NAME\"].fillna('') + \" \" +\n    # data[\"COMPANY_NAME\"].fillna('') + \" \" +\n    data[\"SKU\"].fillna('') + \" \" +\n    # data[\"UNSPSC_DEFINITION\"].fillna('') + \" \" +\n    \n    data[\"BY_NAME_GMDN\"].fillna('') + \" \" +\n    data[\"LONG_DESCRIPTION\"].fillna('') + \" \" +\n    data[\"PRODUCT_DEFINITION\"].fillna('') + \" \" +\n    data[\"DEVICE_DESCRIPTION\"].fillna('') + \" \" +\n    data[\"DEVICE_DESCRIPTION_CLEAN_LONG\"].fillna('') + \" \" +\n    # data[\"DEVICE_TXT\"].fillna('') + \" \" +\n    # data[\"DEVICE_CATEGORY_PATH\"].fillna('') + \" \" +\n    # data[\"DEVICE_ATTRIBUTE_ASSORTMENT_GMDN\"].fillna('') + \" \" +\n    # data[\"DEVICE_DESCRIPTION_254_NO_FLAG\"].fillna('') + \" \" +\n    data[\"DEVICE_CLINICAL_DESCRIPTION_300\"].fillna('')\n)\n\n# Extract the first part of each description before the first '.'\ndata['BY_USE_GMDN_CAT'] = data['BY_USE_GMDN'].astype(str).apply(lambda x: x.split('(')[0])\ndata['BY_USE_GMDN_CAT'] = data['BY_USE_GMDN_CAT'].astype(str).str.strip()\ncategory_map = {\n    \"Anaesthesia and respiratory devices\": \"Anaesthesia, Pulmonary, and Respiratory Devices\",\n    \"Pulmonary devices\": \"Anaesthesia, Pulmonary, and Respiratory Devices\",\n    \"Cardiovascular devices\": \"Cardiovascular Devices\",\n    \"Gastro-urological devices\": \"Endoscopic and Gastro-Urological Devices\",\n    \"Endoscopic devices\": \"Endoscopic and Gastro-Urological Devices\",\n    \"Body fluid and tissue management devices\": \"General Hospital Devices\",\n    \"Body tissue manipulation and reparation devices\": \"General Hospital Devices\",\n    \"General hospital devices\": \"General Hospital Devices\",\n    \"Dermatological and soft-tissue reconstructive/cosmetic devices\": \"Dermatological, Plastic, and Cosmetic Surgery Devices\",\n    \"Plastic surgery and cosmetic devices\": \"Dermatological, Plastic, and Cosmetic Surgery Devices\",\n    \"Dental devices\": \"Dental/Maxillofacial Devices\",\n    \"Dental/Maxillofacial devices\": \"Dental/Maxillofacial Devices\",\n    \"Complementary therapy devices\": \"General Hospital Devices\",\n    \"Disability-assistive products\": \"General Hospital Devices\",\n    \"Physical therapy devices\": \"General Hospital Devices\",\n    \"Ear/Nose/Throat\": \"Neurological and ENT Devices\",\n    \"Neurological devices\": \"Neurological and ENT Devices\",\n    \"In vitro diagnostic medical devices\": \"Laboratory and Diagnostic Devices\",\n    \"Laboratory instruments and equipment\": \"Laboratory and Diagnostic Devices\",\n    \"Obstetrical/Gynaecological devices\": \"Obstetrical and Gynaecological Devices\",\n    \"Ophthalmic devices\": \"Ophthalmic Devices\",\n    \"Orthopaedic devices\": \"Orthopaedic Devices\",\n    \"Radiological devices\": \"Laboratory and Diagnostic Devices\",\n    \"Healthcare facility products and adaptations\": \"General Hospital Devices\"\n}\ndata[\"HighLevelCategory\"] = data[\"BY_USE_GMDN_CAT\"].map(category_map)\ndata[\"HighLevelCategory\"].unique()\ndata_agg = data[[\"HighLevelCategory\", \"COMBINED_TEXT\", \"SOURCE_DESCRIPTION\"]]\n\n\ndata.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2ff2cd05-1940-455a-ba85-487e6fac96da",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "import torch\nimport torch.nn.functional as F\nfrom nltk.corpus import stopwords\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import LabelEncoder",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef4e2806-082f-41e5-961b-401f29df28fa",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "print(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0f7e093a-8854-4436-9b93-f731dc72958c",
   "metadata": {
    "name": "cell6",
    "collapsed": false
   },
   "source": "\n# 1) Setup\n"
  },
  {
   "cell_type": "code",
   "id": "f72857cd-1a76-488c-95d3-c5ee624b2906",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "# nltk.download('stopwords')\n#stop_words = set(stopwords.words('english'))\n\nstop_words = [\"i\",\"me\",\"my\",\"myself\",\"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\ndef custom_clean(text):\n    text = str(text).lower()\n    text = re.sub(r'\\b\\d+\\b', '', text)  # Remove standalone numbers\n    text = re.sub(r'[^a-z0-9\\s\\-/]', '', text)  # Keep medically relevant chars\n    tokens = text.split()\n    cleaned_tokens = [t for t in tokens if t not in stop_words and len(t) > 1]\n    return ' '.join(cleaned_tokens)\n# Apply custom text cleaning\ndata_agg[\"SOURCE_DESCRIPTION\"] = data_agg[\"SOURCE_DESCRIPTION\"].apply(custom_clean)\ndata_agg[\"COMBINED_TEXT\"] = data_agg[\"COMBINED_TEXT\"].apply(custom_clean)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a80ac777-98b0-446f-8b04-9ee488ca9c7c",
   "metadata": {
    "name": "cell21",
    "collapsed": false
   },
   "source": "# 1.1 Load the model.zip to stage"
  },
  {
   "cell_type": "code",
   "id": "4b0cf101-4511-4d33-8711-ed5eb6e96dfa",
   "metadata": {
    "language": "sql",
    "name": "cell20"
   },
   "outputs": [],
   "source": "\nLIST @RESEARCH.AAGARWAL.model_stage;\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "844a7a4f-ab91-4e44-883b-f7b15e8c4b00",
   "metadata": {
    "name": "cell22",
    "collapsed": false
   },
   "source": "# 1.2 Download & extract the model.zip from stage"
  },
  {
   "cell_type": "code",
   "id": "f4aa62c0-e51f-4e8d-9649-cad727c9f597",
   "metadata": {
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": "import zipfile\nimport shutil\nimport snowflake.snowpark as snowpark\nfrom snowflake.snowpark.session import Session\n\n\n# Create a Snowflake session\nsession = Session.builder.getOrCreate()\n\n# clean our directory\nmodel_dir = \"extracted_model\"\nif os.path.exists(model_dir):\n    shutil.rmtree(model_dir)  # Remove if exists to start fresh\nos.makedirs(model_dir, exist_ok=True)\n\n# Download to a specific file path\ndownload_path = f\"{model_dir}/models.zip\"\n\n# Download the file\ntry:\n    session.file.get(\"@RESEARCH.AAGARWAL.model_stage/models.zip\", download_path)\n    print(f\"File downloaded to {download_path}\")\n    \n    # Verify the file exists and is a file (not a directory)\n    if os.path.exists(download_path):\n        if os.path.isfile(download_path):\n            print(f\"File size: {os.path.getsize(download_path)} bytes\")\n            \n            # Extract the zip file\n            with zipfile.ZipFile(download_path, 'r') as zip_ref:\n                zip_ref.extractall(model_dir)\n                print(f\"Extraction complete to {model_dir}\")\n                \n                # List extracted contents\n                print(\"Extracted contents:\")\n                for root, dirs, files in os.walk(model_dir):\n                    for file in files:\n                        if file != \"models.zip\":  # Skip the zip file itself\n                            print(f\"  {os.path.join(root, file)}\")\n        else:\n            print(f\"ERROR: {download_path} is a directory, not a file\")\n    else:\n        print(f\"ERROR: {download_path} does not exist after download attempt\")\nexcept Exception as e:\n    print(f\"Error during download or extraction: {e}\")\n    \n    # Let's try an alternative approach\n    print(\"\\nTrying alternative approach...\")\n    \n    # List stage content for debugging\n    result = session.sql(\"LIST @RESEARCH.AAGARWAL.model_stage/\").collect()\n    print(\"Files in stage:\")\n    for row in result:\n        print(f\"  {row['name']}\")\n    \n    # Try direct extract if possible\n    extract_dir = \"models_extract_direct\"\n    os.makedirs(extract_dir, exist_ok=True)\n    try:\n        # Try to get individual files if models.zip was already extracted in the stage\n        session.file.get(\"@RESEARCH.AAGARWAL.model_stage/\", extract_dir, recursive=True)\n        print(f\"Files downloaded directly to {extract_dir}\")\n    except Exception as e2:\n        print(f\"Alternative approach failed: {e2}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69bc4e0e-3bf2-4f9d-b1a6-c7f00b2eed76",
   "metadata": {
    "language": "python",
    "name": "cell24"
   },
   "outputs": [],
   "source": "import glob\n\n# First, let's check what's in the stage\nresult = session.sql(\"LIST @RESEARCH.AAGARWAL.model_stage/\").collect()\nprint(\"Files in stage:\")\nfor row in result:\n    print(f\"  {row['name']}\")\n\n# Try to get all files from the stage directly\nprint(\"\\nDownloading files from stage...\")\ntry:\n    session.file.get(\"@RESEARCH.AAGARWAL.model_stage/\", model_dir)\n    print(f\"Files downloaded to {model_dir}\")\n    \n    # Check what was downloaded\n    print(\"\\nDownloaded contents:\")\n    for root, dirs, files in os.walk(model_dir):\n        level = root.replace(model_dir, '').count(os.sep)\n        indent = ' ' * 4 * level\n        print(f\"{indent}{os.path.basename(root)}/\")\n        sub_indent = ' ' * 4 * (level + 1)\n        for file in files:\n            print(f\"{sub_indent}{file}\")\n            \n    # Look for ZIP files that might need extraction\n    zip_files = glob.glob(f\"{model_dir}/**/*.zip\", recursive=True)\n    for zip_path in zip_files:\n        print(f\"\\nFound zip file: {zip_path}\")\n        extract_dir = os.path.dirname(zip_path)\n        print(f\"Extracting to: {extract_dir}\")\n        try:\n            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n                zip_ref.extractall(extract_dir)\n            print(\"Extraction successful\")\n        except Exception as e:\n            print(f\"Error extracting {zip_path}: {e}\")\n            \n    # If no zip files found, the contents might already be extracted\n    if not zip_files and os.path.isdir(f\"{model_dir}/models.zip\"):\n        print(\"\\nIt seems 'models.zip' is already a directory with extracted contents.\")\n        # Rename for clarity\n        if os.path.exists(f\"{model_dir}/models.zip\"):\n            os.rename(f\"{model_dir}/models.zip\", f\"{model_dir}/models_extracted\")\n            print(\"Renamed 'models.zip' directory to 'models_extracted'\")\n    \n    # Check if we have the expected model files\n    model_files = glob.glob(f\"{model_dir}/**/pytorch_model.bin\", recursive=True)\n    if model_files:\n        print(\"\\nFound model files:\")\n        for model_file in model_files:\n            print(f\"  {model_file}\")\n    else:\n        print(\"\\nNo pytorch_model.bin files found in the extracted content.\")\n        \nexcept Exception as e:\n    print(f\"Error during download: {e}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3d1c7e1b-fcfe-4397-9b0c-93840fe6b639",
   "metadata": {
    "name": "cell8",
    "collapsed": false
   },
   "source": "# 2) Load Pretrained Model (Local Path)"
  },
  {
   "cell_type": "code",
   "id": "a3e1d421-7772-40a9-bc7b-918df7b9d793",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "######### TO-DO : get the model\n\nmodel_path = r\"extracted_model/models.zip/models\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModel.from_pretrained(model_path)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "598d1e8f-e6be-465f-8f84-87863986d188",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "# 3) Create Dataset (Contrastive Learning)"
  },
  {
   "cell_type": "code",
   "id": "d103ef04-c9cb-4e78-869c-bdb8ddec150c",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "class MedicalDataset(Dataset):\n    \"\"\" Dataset for training embeddings using contrastive learning. \"\"\"\n    def __init__(self, df):\n        self.text_pairs = list(zip(df[\"COMBINED_TEXT\"], df[\"SOURCE_DESCRIPTION\"]))\n    def __len__(self):\n        return len(self.text_pairs)\n    def __getitem__(self, idx):\n        return self.text_pairs[idx]\ndataset = MedicalDataset(data_agg)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4aca2452-704a-4df1-8b6f-4dabf55f1a0f",
   "metadata": {
    "name": "cell12",
    "collapsed": false
   },
   "source": "# 4) Collate Function (Tokenization)"
  },
  {
   "cell_type": "code",
   "id": "0c86a816-eca0-41fc-b7a6-eaf44f73ab46",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": "def collate_fn(batch):\n    combined_texts = [b[0] for b in batch]\n    source_texts = [b[1] for b in batch]\n    enc_combined = tokenizer(combined_texts, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n    enc_source = tokenizer(source_texts, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n    return {k: v.to(device) for k, v in enc_combined.items()}, {k: v.to(device) for k, v in enc_source.items()}\ntrain_loader = DataLoader(\n    dataset,\n    batch_size=32,\n    shuffle=True,\n    collate_fn=collate_fn\n)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1f2c1823-5c0f-4ef7-b6ce-0cadd066ad05",
   "metadata": {
    "name": "cell14",
    "collapsed": false
   },
   "source": "# 5) Mean Pooling (Convert BERT Output to Sentence Embeddings)"
  },
  {
   "cell_type": "code",
   "id": "9ac511bc-bc69-4758-8e0a-3ba6a8069b3b",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": "def mean_pooling(last_hidden_state, attention_mask):\n    \"\"\" Mean Pooling for sentence embeddings. \"\"\"\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size())\n    sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n    return sum_embeddings / sum_mask",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "07f9c3ef-8572-4e3f-9cce-5e98daaa1a10",
   "metadata": {
    "name": "cell16",
    "collapsed": false
   },
   "source": "# 6) Loss Function: Multiple Negatives Ranking Loss"
  },
  {
   "cell_type": "code",
   "id": "efc8b08a-b3cb-48a4-a321-cef30e0db204",
   "metadata": {
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": "def multiple_negatives_ranking_loss(embeddings_a, embeddings_b):\n    \"\"\"\n    - Contrastive loss comparing each row in embeddings_a against all other rows.\n    - Diagonal elements are the positive pairs.\n    \"\"\"\n    embeddings_a = F.normalize(embeddings_a, p=2, dim=1)\n    embeddings_b = F.normalize(embeddings_b, p=2, dim=1)\n    scores = torch.matmul(embeddings_a, embeddings_b.T)\n    labels = torch.arange(scores.size(0), device=scores.device)\n    loss_fct = torch.nn.CrossEntropyLoss()\n    return loss_fct(scores, labels)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9fef53b5-65be-4a13-a7eb-4cefad2e51dc",
   "metadata": {
    "name": "cell18",
    "collapsed": false
   },
   "source": "# 7) Training Loop (Contrastive Learning)"
  },
  {
   "cell_type": "code",
   "id": "696eb26b-97c7-40d9-95f5-d683a3cf1e91",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": "optimizer = AdamW(model.parameters(), lr=2e-5)\nepochs = 3\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0.0\n    \n    for enc_combined, enc_source in train_loader:\n        optimizer.zero_grad()\n        \n        # Forward pass for COMBINED_TEXT\n        out_c = model(**enc_combined)\n        embeddings_c = mean_pooling(out_c.last_hidden_state, enc_combined[\"attention_mask\"])\n        # Forward pass for SOURCE_DESCRIPTION\n        out_s = model(**enc_source)\n        embeddings_s = mean_pooling(out_s.last_hidden_state, enc_source[\"attention_mask\"])\n        # Compute contrastive loss\n        loss = multiple_negatives_ranking_loss(embeddings_c, embeddings_s)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    print(f\"Epoch {epoch+1}/{epochs}, Loss={total_loss:.4f}\")",
   "execution_count": null
  }
 ]
}
